{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ee03ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries and load the model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the IMDB dataset word index\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd0998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "## Load the pre-trained model\n",
    "model = load_model('simple_rnn_imdb_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Helper \n",
    "# function to decode reviews\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review]) # Adjusting index by 3 as per Keras documentation\n",
    "\n",
    "# function to preprocess input text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    words = text.lower().split()\n",
    "    # Convert words to their respective indices based on the IMDB word index\n",
    "    encoded_review = [word_index.get(word, 2) + 3 for word in words]  # +3 to account for reserved encoded_review\n",
    "    # Pad the sequence to ensure uniform input length\n",
    "    padded_review = sequence.pad_sequences([encoded_review], maxlen=500)\n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c4cea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction function\n",
    "def predict_sentiment(review):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_review = preprocess_text(review)\n",
    "    # Make prediction using the loaded model\n",
    "    prediction = model.predict(preprocessed_review)\n",
    "    # Interpret the prediction\n",
    "    sentiment = \"Positive\" if prediction[0][0] > 0.5 else \"Negative\"\n",
    "    return sentiment, prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d8a2347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Review: The movie was fantastic! The acting was great and the plot was thrilling.\n",
      "Predicted Sentiment: Negative (Score: 0.0292)\n"
     ]
    }
   ],
   "source": [
    "## Step 4: User Input and Prediction\n",
    "# Example usage\n",
    "example_review = \"The movie was fantastic! The acting was great and the plot was thrilling.\"\n",
    "sentiment, score = predict_sentiment(example_review)\n",
    "print(f\"Review: {example_review}\\nPredicted Sentiment: {sentiment} (Score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa831b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a69b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d95495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b3414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b650b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0a329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c0696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ef8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739a8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
